{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "x = np.random.uniform(0.1,5,100)\n",
    "noise = np.random.normal(scale=0.3, size=x.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuition: factorization\n",
    "Why is it useful to express something as a few parts multiplied together?\n",
    "To convey more information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at what points does y=0?\n",
    "# y = -x**3 + 7*x**2 - 14*x + 8\n",
    "y = (4-x) * (2-x) * (1-x)\n",
    "#x = independant\n",
    "# y = dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"x\": x, \"y\": y+noise}).plot.scatter(x=\"x\", y=\"y\")\n",
    "plt.hlines(0, -1, 6, color=\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some cool dimensionality reduction examples:\n",
    "https://pair-code.github.io/understanding-umap/ \\\n",
    "https://distill.pub/2016/misread-tsne/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.normal(size=(9, 7))\n",
    "B = np.random.normal(size=(7, 14))\n",
    "C = np.random.normal(size=(14, 3))\n",
    "D = np.random.normal(size=(3, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A.shape, B.shape, C.shape, D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. The matrix multiplication is possible when the second & first sizes of consecutive matrices match\n",
    "# 2. size of the final: row of the first matrix, and column of the last\n",
    "(A @ B @ C @ D).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Is it possible to use fewer columns to represent this dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(make_blobs(centers=2, random_state=320)[0], columns=[\"A\", \"B\"])\n",
    "df[\"C\"] = df[\"A\"] * 2\n",
    "df[\"D\"] = df[\"A\"] - df[\"B\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: Yes. C is two times of A and D is A - B, so we only need A & B and their relationship to C & D to represent the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Decomposition with Principal Component Analysis (PCA)\n",
    "\n",
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition\n",
    "\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PCA()\n",
    "W = p.fit_transform(df)\n",
    "C = p.components_\n",
    "m = p.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to use W and C to reconstruct the original dataframe\n",
    "pd.DataFrame(W @ C).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA will first find the mean\n",
    "m = p.mean_\n",
    "print(m.shape)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use W and C to reconstruct the original dataframe\n",
    "pd.DataFrame((W @ C) + m).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C is called the **component matrix** \\\n",
    "first row of C is the most important component \\\n",
    "second row of C is the second most important component \\\n",
    "and so on ...\n",
    "\n",
    "Each row is in the form of the slope of the componenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two components for 2d data\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first component, PCA will try to fit a line that corss the mean point and \n",
    "has the largest spreadout in terms of points. \\\n",
    "The second component will be prependicular to the first component, corssing the mean point, \n",
    "and has the largest spreadout in its direction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First column of W represents relative positions of points along the first component \\\n",
    "Second column of W represents relative positions of points along the second component \\\n",
    "and so on ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(W.shape, C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# us the first two components to reconstruct the dataframe\n",
    "pd.DataFrame(W[:, :2] @ C[:2, :] + m).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only the first component to approximately reconstruct the dataframe\n",
    "# the first column of W (relative position of W along the first component) multiply the first row of C (the first component)\n",
    "pd.DataFrame(W[:, :1] @ C[:1, :] + p.mean_).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explained Variance\n",
    " * Let's check how close the above dataframe to the orginal dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1.1, 1.9, 3.2])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([1, 2, 3])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = a.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after = (a - b).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improvement = (before - after)/before\n",
    "improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - (a - b).var() / a.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the amount of variance explained by each components\n",
    "# the first component has largest explained variance ratio\n",
    "# the second component has the second largest explained variance ratio\n",
    "# and so on \n",
    "explained_variance = p.explained_variance_.round(2)\n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(explained_variance / explained_variance.sum()).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explained variance percentage wise\n",
    "p.explained_variance_ratio_.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative plot of explained variance ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumsum() compute the cumulative sum\n",
    "s = pd.Series(p.explained_variance_ratio_.cumsum(), index=range(1,5))\n",
    "ax = s.plot.line()\n",
    "ax.set_ylabel(\"Cumulative Explained Variance\")\n",
    "ax.set_xlabel(\"Number of Components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumsum() compute the cumulative sum\n",
    "s = pd.Series(p.explained_variance_ratio_.cumsum(), index=range(1,5))\n",
    "ax = s.plot.line(ylim=0)\n",
    "ax.set_ylabel(\"Cumulative Explained Variance\")\n",
    "ax.set_xlabel(\"Number of Components\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction on Feature Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the W columns for machine leearning and visualization, because this tells\n",
    "# us a lot about the original 4 columns\n",
    "pd.DataFrame(W).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass an int to say how many weight columns and component rows we want to slice out\n",
    "p = PCA(2)\n",
    "W = p.fit_transform(df)\n",
    "C = p.components_\n",
    "m = p.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(W.shape, C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass a float to indicate how much variance we want to explain (explained_variance_ratio_}\n",
    "p = PCA(0.96)\n",
    "W = p.fit_transform(df)\n",
    "C = p.components_\n",
    "m = p.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(W.shape, C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"pca\", PCA(2)), \n",
    "    (\"km\", KMeans(3)),\n",
    "])\n",
    "\n",
    "# pipe.fit_transform(df) # fit PCA, transform using PCA, fit KMeans using output from PCA\n",
    "\n",
    "groups = pipe.fit_predict(df)\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe[\"pca\"].transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pipe[\"pca\"].transform(df)).plot.scatter(x=0, y=1, c=groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lossy Compression\n",
    "\n",
    "Use PCA to extract the most important information and throw away the less important ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread(\"bug.jpg\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaging the color dimension to make it a bit more easy to handle\n",
    "img = img.mean(axis=2)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to explian 95% of the variance\n",
    "p = PCA(0.95)\n",
    "W = p.fit_transform(img)\n",
    "C = p.components_\n",
    "m = p.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_size = len(img.reshape(-1))\n",
    "original_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_size = len(W.reshape(-1)) + len(C.reshape(-1)) + len(m.reshape(-1))\n",
    "compressed_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compression ratio\n",
    "original_size / compressed_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(W @ C + m, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves numpy arrays into .npz format\n",
    "# use wb to write in binary format\n",
    "with open(\"img1.npz\", \"wb\") as f: \n",
    "    np.savez(f, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"img2.npz\", \"wb\") as f: \n",
    "    np.savez(f, W, C, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(\"img2.npz\") as f: \n",
    "    W, C, m = f.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(W @ C + m, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original plot size vs the compressed plot size\n",
    "!ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
